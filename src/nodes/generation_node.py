#!/usr/bin/env python3
"""
Generation Node - Handles LLM conversation generation
"""

import asyncio
import psycopg2
import json
import uuid
import socket
import aiohttp
from datetime import datetime
from pathlib import Path

class GenerationNode:
    def __init__(self, llm_endpoint="http://127.0.0.1:1234/v1/chat/completions", max_jobs=None):
        self.db_config = {
            'host': 'EPM_DELL',
            'port': 5432,
            'database': 'calllab',
            'user': 'postgres',
            'password': 'pass'
        }
        self.llm_endpoint = llm_endpoint
        self.node_id = str(uuid.uuid4())
        self.hostname = socket.gethostname()
        self.running = False
        self.max_jobs = max_jobs
        self.jobs_processed = 0
        
    def get_db(self):
        """Get database connection"""
        return psycopg2.connect(**self.db_config)
    
    async def register_node(self):
        """Register this node with the master"""
        conn = self.get_db()
        
        cur = conn.cursor()
        
        # Check if node already exists
        cur.execute(
            "SELECT id FROM nodes WHERE hostname = %s AND node_type = 'generation'", 
            (self.hostname,)
        )
        existing = cur.fetchone()
        
        if existing:
            self.node_id = existing[0]
            # Update status
            cur.execute(
                "UPDATE nodes SET status = 'online', last_seen = %s WHERE id = %s",
                (datetime.now(), self.node_id)
            )
        else:
            # Register new node
            cur.execute(
                "INSERT INTO nodes (id, hostname, node_type, status, capabilities) VALUES (%s, %s, %s, %s, %s)",
                (self.node_id, self.hostname, "generation", "online", json.dumps(["llm_generation"]))
            )
        
        cur.close()
        
        conn.commit()
        conn.close()
        
        print(f"ðŸ“ Registered generation node: {self.node_id[:8]} ({self.hostname})")
    
    async def start(self):
        """Start the generation node"""
        print("ðŸ¤– Starting Generation Node")
        
        try:
            conn = self.get_db()
            conn.close()
        except Exception as e:
            print(f"âŒ Database connection failed: {e}")
            return
        
        await self.register_node()
        self.running = True
        
        # Start background tasks
        tasks = [
            asyncio.create_task(self.job_processor_loop()),
            asyncio.create_task(self.heartbeat_loop())
        ]
        
        print("âœ… Generation node online")
        print(f"ðŸ”— LLM endpoint: {self.llm_endpoint}")
        
        try:
            await asyncio.gather(*tasks)
        except KeyboardInterrupt:
            print("\nðŸ›‘ Shutting down...")
            await self.shutdown()
    
    async def job_processor_loop(self):
        """Process assigned generation jobs"""
        while self.running:
            conn = self.get_db()
            cur = conn.cursor()
            
            # Get jobs assigned to this node
            cur.execute(
                "SELECT id, scenario_id, parameters FROM jobs WHERE assigned_node_id = %s AND status = 'running' LIMIT 1",
                (self.node_id,)
            )
            job = cur.fetchone()
            
            if job:
                job_id, scenario_id, parameters = job
                params = parameters if isinstance(parameters, dict) else json.loads(parameters or "{}")
                
                print(f"ðŸ”„ Processing job: {job_id[:8]}")
                
                try:
                    # Generate conversation
                    conversation = await self.generate_conversation(scenario_id, params)
                    
                    if conversation:
                        # Extract metadata
                        metadata = conversation.pop("_metadata", {})
                        
                        # Save conversation
                        conv_id = str(uuid.uuid4())
                        cur.execute(
                            """INSERT INTO conversations 
                               (id, job_id, scenario_id, content, quality_score, model_name, 
                                generation_start_time, generation_end_time, generation_duration_ms, evaluation_metrics) 
                               VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s)""",
                            (conv_id, job_id, scenario_id, json.dumps(conversation), 0.8,
                             metadata.get("model_name"), metadata.get("start_time"), 
                             metadata.get("end_time"), metadata.get("duration_ms"), 
                             json.dumps({"realness_score": None, "speed_score": None, "gan_score": None}))
                        )
                        
                        # Mark job complete
                        cur.execute(
                            "UPDATE jobs SET status = 'completed', completed_at = %s WHERE id = %s",
                            (datetime.now(), job_id)
                        )
                        
                        print(f"âœ… Completed job: {job_id[:8]} -> conversation: {conv_id[:8]}")
                        
                        # Check if we've hit the job limit (only count successful jobs)
                        self.jobs_processed += 1
                        if self.max_jobs and self.jobs_processed >= self.max_jobs:
                            print(f"ðŸŽ¯ Reached job limit ({self.max_jobs}), shutting down...")
                            self.running = False
                            return
                    else:
                        # Mark job failed (don't increment counter)
                        cur.execute(
                            "UPDATE jobs SET status = 'failed' WHERE id = %s", (job_id,)
                        )
                        print(f"âŒ Failed job: {job_id[:8]} - not counting toward limit")
                
                except Exception as e:
                    print(f"âŒ Error processing job {job_id[:8]}: {e}")
                    cur.execute(
                        "UPDATE jobs SET status = 'failed' WHERE id = %s", (job_id,)
                    )
                    print(f"âŒ Job failed due to exception - not counting toward limit")
                
                conn.commit()
            
            cur.close()
            conn.close()
            await asyncio.sleep(5)  # Check every 5 seconds
    
    async def get_available_model(self):
        """Get first available model from LM Studio using config"""
        try:
            # Get first available model from API
            async with aiohttp.ClientSession() as session:
                async with session.get(f"{self.llm_endpoint.replace('/chat/completions', '/models')}", timeout=10) as resp:
                    if resp.status == 200:
                        data = await resp.json()
                        models = data.get("data", [])
                        if models:
                            return models[0]["id"]
        except Exception as e:
            print(f"âš ï¸ Could not get models, using default: {e}")
        
        return "microsoft/phi-4-mini-reasoning"  # Fallback
    
    async def generate_conversation(self, scenario_id, parameters):
        """Generate a conversation using LLM"""
        conn = self.get_db()
        cur = conn.cursor()
        
        # Get scenario template
        cur.execute(
            "SELECT name, template FROM scenarios WHERE id = %s", (scenario_id,)
        )
        scenario = cur.fetchone()
        
        cur.close()
        conn.close()
        
        if not scenario:
            return None
        
        scenario_name, template = scenario
        min_turns = parameters.get("min_turns", 20)
        max_turns = parameters.get("max_turns", 40)
        
        # Get available model
        model_name = await self.get_available_model()
        
        # Build prompt
        prompt = f"""Generate a realistic conversation for: {scenario_name}

{template}

Requirements:
- Length: {min_turns} to {max_turns} turns
- Format: alternating User: and Agent: lines
- Natural, realistic dialogue
- Include realistic hesitations and corrections

Generate ONLY the conversation, no commentary:"""
        
        start_time = datetime.now()
        
        try:
            # Call LLM
            async with aiohttp.ClientSession() as session:
                payload = {
                    "model": model_name,
                    "messages": [{"role": "user", "content": prompt}],
                    "temperature": 0.9,
                    "max_tokens": 2000
                }
                
                async with session.post(self.llm_endpoint, json=payload, timeout=60) as resp:
                    end_time = datetime.now()
                    duration_ms = int((end_time - start_time).total_seconds() * 1000)
                    
                    if resp.status == 200:
                        data = await resp.json()
                        text = data.get("choices", [{}])[0].get("message", {}).get("content", "")
                        
                        # Convert to Contact Lens format and add metadata
                        conversation = self.format_conversation(text, scenario_name)
                        conversation["_metadata"] = {
                            "model_name": model_name,
                            "start_time": start_time.isoformat(),
                            "end_time": end_time.isoformat(),
                            "duration_ms": duration_ms
                        }
                        
                        return conversation
                    else:
                        print(f"âŒ LLM API error: {resp.status}")
                        return None
        
        except Exception as e:
            print(f"âŒ LLM call failed: {e}")
            return None
    
    def format_conversation(self, text, scenario_name):
        """Convert raw text to Contact Lens format"""
        lines = [line.strip() for line in text.split('\n') if line.strip()]
        turns = []
        
        for line in lines:
            if line.startswith("User:"):
                turns.append(("CUSTOMER", line[5:].strip()))
            elif line.startswith("Agent:"):
                turns.append(("AGENT", line[6:].strip()))
        
        # Build Contact Lens format
        return {
            "Participants": [
                {"ParticipantId": "A1", "ParticipantRole": "AGENT"},
                {"ParticipantId": "C1", "ParticipantRole": "CUSTOMER"}
            ],
            "Version": "1.1.0",
            "ContentMetadata": {"RedactionTypes": ["PII"], "Output": "Raw"},
            "CustomerMetadata": {"ContactId": str(uuid.uuid4())},
            "Transcript": [
                {
                    "ParticipantId": "C1" if role == "CUSTOMER" else "A1",
                    "Id": f"T{i:06d}",
                    "Content": content
                }
                for i, (role, content) in enumerate(turns, 1)
            ]
        }
    
    async def heartbeat_loop(self):
        """Send heartbeat to master"""
        while self.running:
            conn = self.get_db()
            cur = conn.cursor()
            cur.execute(
                "UPDATE nodes SET last_seen = %s WHERE id = %s",
                (datetime.now(), self.node_id)
            )
            conn.commit()
            cur.close()
            conn.close()
            
            await asyncio.sleep(30)  # Heartbeat every 30 seconds
    
    async def shutdown(self):
        """Shutdown the node"""
        self.running = False

if __name__ == "__main__":
    import sys
    max_jobs = int(sys.argv[1]) if len(sys.argv) > 1 else None
    node = GenerationNode(max_jobs=max_jobs)
    asyncio.run(node.start())