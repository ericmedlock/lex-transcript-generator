<div style="display: flex; flex-direction: column; align-items: center; justify-content: center; text-align: center; padding: 200px 0 20px 0;">

<div style="font-size: 24px; margin-bottom: 12px;"><strong>Amazon Q</strong></div>
<div style="background: rgba(128, 128, 128, 0.15); border: 1px solid rgba(128, 128, 128, 0.25); border-radius: 8px; padding: 8px; margin: 4px 0; text-align: center;">
<div style="font-size: 14px; margin-bottom: 4px;"><strong>Did you know?</strong></div>
<div>MCP is available in Amazon Q!</div>
</div>

Select code & ask me to explain, debug or optimize it, or type `/` for quick actions

</div>

---

Looking at all the directories/subdirectories under Training Datasets. I think I&#39;d like a tool/preprocessor that can read ALL of these files and categorize them, then built &quot;templates&quot; based on the variety found to use for prompt injection. 

DO NOT BUILD ANYTHING YET: 

Tell me how you&#39;d do that, think two or three levels deep, should either use local LLMs or open AI API (capable of either based on cofing/command line) and so forth. Tell me how this would all work

---

I'll analyze your Training Datasets directory first to understand the current structure and data types, then propose a comprehensive categorization and template generation system.

---


Based on my analysis of your Training Datasets structure, here's how I'd design a comprehensive categorization and template generation system:

## System Architecture

### **Level 1: Data Discovery & Categorization**

**File Scanner & Analyzer**
- Recursive directory traversal with file type detection
- Multi-format parser (JSON, CSV, TXT, XML, etc.)
- Content structure analysis (conversation vs. monologue, speaker count, domain indicators)
- Metadata extraction (timestamps, confidence scores, PII markers)

**Smart Categorization Engine**
- **Domain Classification**: Healthcare, retail, telecom, finance, etc. using keyword analysis and LLM classification
- **Conversation Type**: Customer service, appointment booking, technical support, sales calls
- **Quality Metrics**: Transcript completeness, speaker clarity, conversation flow
- **Structural Patterns**: Turn-taking patterns, conversation length, interruption frequency

### **Level 2: Pattern Recognition & Template Extraction**

**Conversation Flow Analyzer**
- Opening patterns (greetings, company identification)
- Middle patterns (problem resolution, information gathering)
- Closing patterns (next steps, farewells)
- Common phrases and response templates per domain

**Template Generator**
- **Structural Templates**: Speaker alternation patterns, conversation length distributions
- **Content Templates**: Domain-specific vocabulary, common scenarios, emotional tones
- **Prompt Templates**: Situation setups, character descriptions, outcome goals

### **Level 3: LLM Integration & Generation**

**Configurable LLM Backend**
```python
# Command line configurable
--llm-provider openai|local|ollama
--model gpt-4|llama3|mistral
--endpoint http://localhost:1234/v1
```

**Template-Driven Prompt Engineering**
- Dynamic prompt construction from discovered patterns
- Few-shot examples from similar conversations
- Domain-specific constraints and requirements
- Quality control prompts for validation

## Implementation Strategy

### **Core Components**

1. **DatasetAnalyzer**: Scans all files, extracts metadata, identifies patterns
2. **TemplateEngine**: Converts patterns into reusable generation templates
3. **PromptBuilder**: Constructs LLM prompts using templates + user requirements
4. **QualityValidator**: Ensures generated content matches discovered patterns

### **Template Categories**

**Structural Templates**
- Conversation length: `{min_turns: 8, max_turns: 25, avg_turns: 15}`
- Speaker patterns: `{customer_first: true, agent_dominance: 0.6}`
- Timing patterns: `{response_delay: "1-3s", overlap_frequency: 0.1}`

**Content Templates**
- Domain vocabulary: `{medical_terms: [...], procedures: [...], emotions: [...]}`
- Scenario frameworks: `{appointment_booking, insurance_inquiry, test_results}`
- Personality archetypes: `{frustrated_customer, helpful_agent, confused_caller}`

**Generation Templates**
```yaml
healthcare_appointment:
  setup: "Generate a conversation between a patient calling to schedule..."
  constraints: 
    - Include insurance verification
    - 15-30 exchanges
    - Professional but empathetic tone
  examples: [extracted from similar conversations]
```

### **Usage Flow**

1. **Analysis Phase**: `python analyze_datasets.py --scan-all --output templates.json`
2. **Template Review**: Web interface to review/edit discovered templates
3. **Generation**: `python generate.py --template healthcare_appointment --count 100 --llm openai`

This approach leverages your existing data to create highly realistic templates while remaining flexible for both local and cloud LLM usage. The system would automatically adapt to new data patterns and continuously improve template quality.

---

yes, pretty good! Only thing I think I&#39;d add is the concept of a sub-category. ie: &quot;healthcare appointments&quot; - category, &quot;Same day sick appointment&quot; - subcategory.... &quot;Annual checkup&quot; - subcategory, etc. 

So, don&#39;t generate, just acknowledge and let me knw your thoughts

---


Excellent addition! The hierarchical categorization makes perfect sense and would dramatically improve template precision.

## Enhanced Categorization Structure

**Three-Tier Hierarchy:**
- **Domain** (Healthcare, Retail, Telecom)
- **Category** (Appointments, Billing, Support)  
- **Subcategory** (Same-day sick, Annual checkup, Specialist referral)

This would enable:

**More Targeted Templates**
- Each subcategory gets its own conversation patterns, vocabulary, and flow
- "Same-day sick" = urgent tone, symptom discussion, availability focus
- "Annual checkup" = routine tone, scheduling flexibility, preventive care

**Better Pattern Recognition**
- LLM can identify subtle differences: "I need to see someone today" vs "I'd like to schedule my yearly physical"
- Subcategory-specific phrase libraries and emotional contexts

**Granular Generation Control**
```bash
python generate.py --domain healthcare --category appointments --subcategory same_day_sick --count 50
```

**Template Inheritance**
- Subcategories inherit domain/category patterns but override with specific behaviors
- Reduces template redundancy while maintaining specificity

This hierarchical approach would create much more realistic and varied conversations since each subcategory would have distinct characteristics, vocabulary, and flow patterns extracted from your actual data.

The analyzer would need to be smart enough to detect these nuanced differences - probably requiring LLM assistance for the subcategory classification step.

---

great! 

So, create a new module/tool in its own subdirectory/set of directories (I intend to lift/shift this out of this project into a stand alone project, but today I just need something that works).  

Right now, just outline the functional/non-functional requirements for this tool

---


# Dataset Analyzer & Template Generator Tool

## Directory Structure
```
dataset_analyzer/
├── src/
│   ├── analyzer/
│   ├── templates/
│   ├── llm/
│   └── utils/
├── config/
├── output/
├── tests/
└── requirements.txt
```

## Functional Requirements

### Core Analysis Functions
- **F1**: Recursively scan directory structures for conversation files
- **F2**: Parse multiple formats (JSON, CSV, TXT, XML) with auto-detection
- **F3**: Extract conversation metadata (speaker count, turn count, timestamps, confidence scores)
- **F4**: Classify conversations into Domain → Category → Subcategory hierarchy
- **F5**: Identify structural patterns (opening/middle/closing flows, response patterns)
- **F6**: Extract domain-specific vocabulary and phrase libraries
- **F7**: Generate reusable conversation templates with inheritance

### Template Generation
- **F8**: Create prompt templates for LLM generation with few-shot examples
- **F9**: Support template inheritance (subcategory inherits from category/domain)
- **F10**: Export templates in multiple formats (JSON, YAML, Python objects)

### LLM Integration
- **F11**: Configurable LLM backends (OpenAI API, local endpoints, Ollama)
- **F12**: Use LLM for intelligent subcategory classification
- **F13**: Generate sample conversations using discovered templates

### User Interface
- **F14**: CLI interface for batch processing and automation
- **F15**: Web interface for template review/editing (optional)
- **F16**: Progress reporting and logging for long-running analysis

## Non-Functional Requirements

### Performance
- **NF1**: Process 10,000+ files without memory issues (streaming/chunking)
- **NF2**: Parallel processing for file analysis
- **NF3**: Incremental analysis (skip unchanged files)

### Reliability
- **NF4**: Graceful handling of malformed/corrupted files
- **NF5**: Resume capability for interrupted analysis runs
- **NF6**: Comprehensive error logging and recovery

### Configurability
- **NF7**: YAML-based configuration for classification rules
- **NF8**: Pluggable LLM providers via unified interface
- **NF9**: Customizable taxonomy (domain/category/subcategory definitions)

### Output Quality
- **NF10**: Deterministic results (same input = same output)
- **NF11**: Confidence scoring for classifications
- **NF12**: Human-readable analysis reports

### Portability
- **NF13**: Standalone operation (minimal external dependencies)
- **NF14**: Cross-platform compatibility (Windows/Linux/Mac)
- **NF15**: Docker containerization support